{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vintage', 'luxury', 'spacious', 'compact', 'durable']\n",
      "6192        Kadai\n",
      "6183    Casserole\n",
      "6182    Casserole\n",
      "6181    Casserole\n",
      "6210         Tawa\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Load data\n",
    "expo_data = pd.read_excel(r\"C:\\Users\\Moksh\\Dropbox\\PC\\Downloads\\Expo Master.xlsx\")\n",
    "\n",
    "# Preprocessing\n",
    "expo_data['cleaned_description'] = expo_data['description'].astype(str).str.replace(\"_x000D_\\n\", \" \").str.strip()\n",
    "expo_data['combined_text'] = expo_data['name'] + \" \" + expo_data['cleaned_description'] + \" \" + expo_data['categories'].astype(str)\n",
    "\n",
    "# Simulate user search history and user ratings\n",
    "def generate_search_terms():\n",
    "    terms = ['durable', 'eco-friendly', 'stylish', 'modern', 'vintage', 'high-quality', 'cheap', 'luxury', 'compact', 'spacious']\n",
    "    return random.sample(terms, random.randint(1, 5))\n",
    "\n",
    "expo_data['user_search_history'] = [generate_search_terms() for _ in range(len(expo_data))]\n",
    "expo_data['user_rating'] = [random.randint(1, 5) for _ in range(len(expo_data))]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.85)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(expo_data['combined_text'])\n",
    "\n",
    "# Content-Based Filtering\n",
    "def get_user_profile(search_history):\n",
    "    profile = \" \".join(expo_data[expo_data['combined_text'].str.contains('|'.join(search_history))]['combined_text'])\n",
    "    return profile\n",
    "\n",
    "def content_based_recommendations(search_history):\n",
    "    user_profile = get_user_profile(search_history)\n",
    "    user_vector = tfidf_vectorizer.transform([user_profile])\n",
    "    cosine_sim_user = linear_kernel(user_vector, tfidf_matrix).flatten()\n",
    "    recommended_indices = cosine_sim_user.argsort()[-10:][::-1]\n",
    "    return recommended_indices\n",
    "\n",
    "# Collaborative Filtering\n",
    "def adjust_by_ratings(recommended_indices, ratings):\n",
    "    recommended_ratings = ratings[recommended_indices]\n",
    "    sorted_indices = [index for _, index in sorted(zip(recommended_ratings, recommended_indices), reverse=True)]\n",
    "    return sorted_indices\n",
    "\n",
    "# Hybrid Recommendation System\n",
    "def hybrid_recommendations(search_history, num_recommendations=5):\n",
    "    recommended_indices = content_based_recommendations(search_history)\n",
    "    final_indices = adjust_by_ratings(recommended_indices, expo_data['user_rating'].values)\n",
    "    return expo_data['name'].iloc[final_indices[:num_recommendations]]\n",
    "\n",
    "# Test the system\n",
    "test_search_history = expo_data['user_search_history'].iloc[1]\n",
    "print(test_search_history)\n",
    "recommended_products = hybrid_recommendations(test_search_history)\n",
    "print(recommended_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Load the updated data\n",
    "updated_expo_data = pd.read_excel(r\"C:\\Users\\Moksh\\Dropbox\\PC\\Downloads\\Updated_Expo_Master_v3.xlsx\")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.85)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(updated_expo_data['combined_text'])\n",
    "\n",
    "# Define the function to simulate user search history\n",
    "def generate_search_terms():\n",
    "    terms = ['durable', 'eco-friendly', 'stylish', 'modern', 'vintage', 'high-quality', 'cheap', 'luxury', 'compact', 'spacious']\n",
    "    return random.sample(terms, random.randint(1, 5))\n",
    "\n",
    "# Function to build user profile based on search history\n",
    "def get_user_profile(search_history):\n",
    "    profile = \" \".join(updated_expo_data[updated_expo_data['combined_text'].str.contains('|'.join(search_history))]['combined_text'])\n",
    "    return profile\n",
    "\n",
    "# Content-Based Filtering incorporating Click Through Rate\n",
    "def content_based_recommendations(search_history):\n",
    "    user_profile = get_user_profile(search_history)\n",
    "    user_vector = tfidf_vectorizer.transform([user_profile])\n",
    "    cosine_sim_user = linear_kernel(user_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Introduce a CTR-based boost\n",
    "    cosine_sim_user = cosine_sim_user * updated_expo_data['click_through_rate'].values\n",
    "    \n",
    "    # Get top 10 product indices based on adjusted similarity\n",
    "    recommended_indices = cosine_sim_user.argsort()[-10:][::-1]\n",
    "    return recommended_indices\n",
    "\n",
    "# Collaborative Filtering adjusted by ratings and conversion rate\n",
    "def adjust_by_ratings_and_conversion(recommended_indices):\n",
    "    recommended_ratings = updated_expo_data['user_rating'].values[recommended_indices]\n",
    "    recommended_conversion = updated_expo_data['conversion_rate'].values[recommended_indices]\n",
    "    \n",
    "    # Weighted sum of ratings and conversion rates to get a combined score for each product\n",
    "    combined_scores = recommended_ratings + recommended_conversion\n",
    "    \n",
    "    # Sort product indices based on combined scores\n",
    "    sorted_indices = [index for _, index in sorted(zip(combined_scores, recommended_indices), reverse=True)]\n",
    "    return sorted_indices\n",
    "\n",
    "# Hybrid Recommendation System\n",
    "def updated_hybrid_recommendations(search_history, num_recommendations=5):\n",
    "    recommended_indices = content_based_recommendations(search_history)\n",
    "    final_indices = adjust_by_ratings_and_conversion(recommended_indices)\n",
    "    return updated_expo_data['name'].iloc[final_indices[:num_recommendations]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10698     Cello Creeper Dinner Set\n",
       "10729    Blooming Daisy Dinner Set\n",
       "10579      Blue Creeper Dinner Set\n",
       "10743    Amazon Creeper Dinner Set\n",
       "4360         Blue Swirl Dinner Set\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the updated system\n",
    "test_search_history = updated_expo_data['user_search_history'].iloc[5]\n",
    "updated_recommended_products = updated_hybrid_recommendations(test_search_history)\n",
    "updated_recommended_products"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
